%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[oneside,brazil,oldfontcommands]{abntex2}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=2cm,lmargin=3cm,rmargin=2cm}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{color}
\usepackage{float}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{accents}
\usepackage{graphicx}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand{\docedilla}[2]{\underaccent{#1\mathchar'30}{#2}}
\newcommand{\cedilla}[1]{\mathpalette\docedilla{#1}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage[alf]{abntex2cite}
\usepackage{indentfirst}
\usepackage{layout}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\usepackage{babel}
\begin{document}


\noindent \begin{center}
\textcolor{black}{\large{}UNIVERSIDADE FEDERAL DO MARANHÃO}
\par\end{center}{\large \par}

\noindent \begin{center}
\textcolor{black}{\large{}CENTRO DE CIÊNCIAS EXATAS E TECNOLÓGICAS}
\par\end{center}{\large \par}

\noindent \begin{center}
\textcolor{black}{\large{}DEPARTAMENTO DE INFORMÁTICA}
\par\end{center}{\large \par}

\noindent \begin{center}
\textcolor{black}{\large{}CURSO DE CIÊNCIA DA COMPUTAÇÃO}
\par\end{center}{\large \par}

\vspace{6cm}


\noindent \begin{center}
\textcolor{black}{\large{}PROJETO DE MONOGRAFIA}
\par\end{center}{\large \par}

\noindent \begin{center}
Análise e Classificação de Termografias Dinâmicas das Mamas Utilizando
a Variação de Temperatura e Máquinas de Vetor de Suporte
\par\end{center}

\vspace{6cm}


\noindent \begin{center}
São Luís
\par\end{center}

\noindent \begin{center}
2016
\par\end{center}

\newpage{}



\vspace{6cm}


\begin{Spacing}{0.5}
\noindent \begin{center}
\rule{7cm}{0.5pt}
\par\end{center}

\noindent \begin{center}
\emph{Caio Nogueira Silva Belfort}
\par\end{center}

\noindent \begin{center}
Aluno do Curso de Ciência da Computação
\par\end{center}
\end{Spacing}

\vspace{2cm}


\begin{Spacing}{0.5}
\noindent \begin{center}
\rule{7cm}{0.5pt}
\par\end{center}

\noindent \begin{center}
\emph{Prof. Dr. Aristófanes Côrrea Silva}
\par\end{center}

\noindent \begin{center}
Orientador
\par\end{center}
\end{Spacing}

\vspace{2cm}


\begin{Spacing}{0.5}
\noindent \begin{center}
\rule{7cm}{0.5pt}
\par\end{center}

\noindent \begin{center}
\emph{Prof. Msc. Carlos Eduardo Portela Serra de Castro}
\par\end{center}

\noindent \begin{center}
Coordenador do Curso de Ciência da Computação
\par\end{center}
\end{Spacing}

\newpage{}
\begin{resumo}
\thispagestyle{empty}

A termografia das mamas é um exame de imagem que utiliza a radiação
infravermelha naturalmente emitida pelo corpo da paciente para detecção
de anomalias. Possui a capacidade de detectar o câncer de mama mais
precocemente que a mamografia, sem causar nenhum efeito colateral
ou incômodo físico na paciente. O processamento de imagens médicas
é uma área que vem ganhando destaque recentemente, pois metodologias
de diagnóstico automático podem auxiliar médicos especialistas na
detecção de doenças de forma precoce, aumentando as chances de cura.
Este trabalho apresenta uma metodologia de processamento e análise
de termografias dinâmicas da mama, como forma de auxiliar médicos
especialista no diagnóstico de doenças relacionadas ao tecido mamário.
O registro de imagens é utilizado para efetuar a correção do erro
de postura entre os diversos tempos de uma termografia dinâmica. Valores
estatísticos são utilizados para medir a variação de temperatura entre
os pixels, formando novas imagens a partir da termografia original.
Em seguida a extração de características de textura é efetuada em
cada imagem estatística, formando um conjunto de valores conhecido
como vetor de características. O vetor de característica é reduzido
através de técnicas de redução de características para posteriormente
servir de entrada para uma máquina de vetor de suporte que irá efetuar
a classificação em exame saudável ou exame com algum tipo de anomalia.
A metodologia apresenta 82,5\% de acurácia, 84,1 \% de sensibilidade
e 81,0\% de especificidade.

Palavras chave: Câncer, Mama, Termografia, Aprendizado de Máquina

\newpage{}
\end{resumo}
\pdfbookmark[0]{\listfigurename}{lof} 
\listoffigures* 
\cleardoublepage

\newpage{}

\pdfbookmark[0]{\contentsname}{toc} 
\tableofcontents* 
\cleardoublepage
\layout


\chapter{Introdução \label{sec:intro}}

O câncer de mama é o tipo mais comum entre as mulheres em todo o mundo,
respondendo por 25\% dos casos a cada ano \cite{inca}. Quando diagnosticado
tardiamente, as chances de cura são extremamente reduzidas, tornando
o diagnóstico precoce um dos fatores mais importantes na redução da
taxa de mortalidade desse tipo de doença. O incidência aumenta juntamente
com a faixa etária, sendo que mulheres acima de 50 anos são mais suscetíveis
ao desenvolvimento da patologia. No entanto, existem outros fatores
de risco que implicam numa maior chance de aparecimento, como o histórico
desse tipo de câncer na família, gestação tardia, terapia de reposição
hormonal e exposição à radiação. 

Os exames mais tradicionais na detecção do câncer de mama são os exames
de toque e a mamografia. O exame de toque é um exame de triagem, onde
o própria mulher pode procurar por nódulos nos seios. Porém, nem sempre
o câncer resulta em aparecimento de nódulos. Dessa forma, a mamografia
se tornou um exame essencial nos dias de hoje, pois utiliza os raios-x
para detectar regiões de alta densidade nas mamas. Apesar de ser o
tipo de exame mais recomendado pelos especialistas, a mamografia é
passível a falhas, já que mamas com alta densidade apresentam um grau
de dificuldade elevado na detecção de tumores, que podem ficar escondidos
pelo tecido denso da mama. Mulheres jovens geralmente apresentam alta
densidade nas mamas, tornando a mamografia um exame não recomendável
para essa faixa etária, pois utiliza a radiação na geração das imagens,
o que pode futuramente causar o aparecimento do câncer na paciente.
Dessa forma é necessário que outros tipo de exames sejam utilizados
como forma de prevenção e diagnóstico precoce.

A termografia mamária é um exame de imagem não radioativo capaz de
auxiliar médicos especialista na detecção tumores que não seriam possíveis
de descobrir através da mamografia. Esse tipo de exame utiliza a radiação
infravermelha, emitida naturalmente pelo corpo da paciente, para detecção
de anomalias no padrão de temperatura das mamas, que pode indicar
algum tipo de doença. Regiões próximas a um tumor tendem a ter um
aumento na vascularização, ocorrendo uma maior circulação de sangue
na região, que causará um aumento de temperatura em relação as outras
regiões da mama. Esse aumento de temperatura é detectável através
da termografia, permitindo que especialistas detectem a formação de
um tumor antes mesmo que ele seja palpável. 

Existem duas formas na obtenção de exames de termografia mamária.
A primeira delas é o que chamamos de termografia estática, onde apenas
uma imagem da paciente é gerada e analisada. A segunda forma é a chamada
termografia dinâmica, onde várias imagens sequenciais são geradas,
permitindo que o especialista analise a evolução na distribuição de
calor nas mamas da paciente. A metodologia proposta utiliza as termografias
dinâmicas para auxiliar médicos especialistas no diagnóstico precoce
do câncer de mama. 

A motivação deste trabalho é ajudar médicos especialistas no diagnóstico
precoce do câncer de mama, portanto qualquer informação que possa
discriminar mamas saudáveis de mamas doentes é relevante. Dessa forma,
várias técnicas de Processamento de Imagens e Aprendizado de Máquina
são utilizadas para aumentar o nível de informação que uma termografia
pode dar ao especialista.

Durante um exame de termografia dinâmico, a paciente executa movimentos
involuntários, causados pela respiração e pelo ajuste de postura,
dessa forma as imagens sequenciais do exame não se encaixam perfeitamente,
causando um erro que pode influenciar na metodologia. O registro de
imagens deformável por \emph{B-Splines }é utilizado para efetuar a
correção desse erro. Posteriormente, extrai-se as regiões de interesse
do exame, que são as mamas da paciente. Essa extração é feita de forma
manual através de um aplicativo, onde o especialista deverá demarcar
a região da mama. Finalmente a etapa de extração de características
é executada, onde os pixels de mesma posição e diferentes tempos da
termografia são analisados como uma série de tempo, produzindo um
conjunto de valores estatísticos para cada pixel, formando novas imagens
a partir da termografia dinâmica original. A partir dessas imagens
geradas, são extraídas o conjunto de características de textura a
partir de matrizes de coocorrência. Essas características podem ser
reduzidas através de técnicas de redução de características como a
técnica de \emph{Análise dos Componentes Principais} e a \emph{Análise
Discriminante Linear. }No final do processo, as características reduzidas
irão servir de entrada para uma \emph{Máquina de Vetor de Suporte}
que irá ser responsável por classificar as pacientes em saudável e
doente. 


\chapter{Objetivos \label{sec:objectives}}


\section{Objetivos Gerais \label{sec:objectives:general_objectives}}

Desenvolver uma metodologia computacional que análise um exame termográfico
dinâmico das mamas, a fim de encontrar padrões que diferenciem mamas
saudáveis de mamas doentes. 


\section{Objetivos Específicos \label{sec:objectives:specific_objectives}}

Alguns objetivos extras são necessários para completar os objetivos
gerais, sendo eles:
\begin{itemize}
\item Desenvolver técnicas que permitam a correção de postura em exames
termográficos dinâmicos. Tais técnicas são conhecidas como registro
de imagens, onde o resultado final pode variar muito de uma técnica
utilizada para outra. Portanto, deve-se utilizar a que melhor se encaixe
no problema.
\item Analisar a variação de temperatura entre os diferentes tempos do exame,
gerando características que sejam capazes de diferenciar os exames
de pacientes saudáveis de exames de pacientes doentes.
\item Utilizar as características extraídas para gerar um classificador
automático, que seja capaz de classificar corretamente novos exames.
\end{itemize}

\chapter{Fundamentação Teórica \label{sec:fundamentation}}

Nesta seção, serão abordados os conceitos necessários para o entendimento
da metologia proposta.


\section{A Termografia \label{sub:fundamentation:termography}}

A termografia é uma técnica que permite a visualização dos raios do
espectro infravermelho de forma a mapear a temperatura de um objeto.
A termografia infravermelha da mama é um tipo de exame que detecta
a radiação infravermelha emitida pela superfície da mama produzindo
um mapa de temperatura conhecido como termograma. A grande vantagem
deste tipo de exame em relação aos exames mais conhecidos, como a
mamografia, é que este não utiliza radiação no processo de obtenção
das imagens e também não causa incômodo físico ao paciente, pois não
é necessário a compressão das mamas, como ocorre na termografia. Outro
fator a se levar em consideração é o custo extremamente baixo e o
fácil manuseio do equipamento necessário para obtenção do exame \cite{borchartt2013breast}.
A Figura \ref{fig:fundamentation:thermography:breast-thermography}
apresenta uma termografia em pseudo cor, onde a temperatura varia
de acordo com a paleta de cores à direita da imagem.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.25]{figures/fundamentation/termography/termography}\caption{Termografia mamária.\label{fig:fundamentation:thermography:breast-thermography}}

\par\end{centering}


\fonte{\cite{silva2014new}}
\end{figure}



\subsection{Termografia Estática\label{sub:fundamentation:termography:static}}

A termografia estática (TI), é o tipo de termografia onde a medição
de temperatura é feita uma única vez. No caso de TI das mamas são
necessários procedimentos \cite{silva2014new} de preparação do ambiente
e cuidados extras ao paciente para que o exame tenha resultado satisfatório,
pois vários fatores podem influenciar o resultado final \cite{lincoln_thesis2015}.


\subsection{Termografia Dinâmica}

A termografia dinâmica (TID), é um tipo de termografia onde a mediação
de temperatura é realizada através de várias etapas de tempo, ou seja,
a TID mede as mudanças de temperatura sobre um determinado período
de tempo. Originalmente conceituada por \cite{anbar1987computerized},
onde notou-se que mudanças bruscas na temperatura da pele produziam
informações valiosas, que não podem ser obtidas por meio de uma TI.

A TID apresenta uma característica importante na detecção de lesões
mamárias, pois áreas saudáveis apresentam um comportamento distinto
de áreas com algum tipo de patologia. Neoplasias são associadas com
a angiogênese que causa um aumento de vascularização na região, sendo
que, os vasos recém formados apresentam a características de possuir
poucas terminações nervosas, o que causa um comportamento irregular
à estímulos externos, que é detectável através de um exame de termografia
dinâmico \cite{lincoln_thesis2015}.

Na prática a TID monitora as mudanças na temperatura da pele, onde
o estimulo térmico através de uma corrente de ar produz um contraste
entre tecidos saudáveis e doentes. Regiões saudáveis da mama tendem
a apresentar uma diminuição de temperatura com o estímulo de ar, enquanto
as regiões doentes tendem a permanecer estáticas \cite{amalu2004nondestructive}. 


\section{Registro de Imagens\label{sec:fundamentation:image_registration}}

Quando imagens que foram extraídas entre diferentes tempos, pontos
de vista ou aparelhos precisam ser comparadas, ocorre um problema
de alinhamento das coordenadas dessas imagens. É necessário efetuar
alguma forma de processamento para que essas imagens possam ser comparadas
adequadamente .\emph{ }O \emph{Registro de Imagens }é uma técnica
que utiliza uma transformação $T$ para mapear a posição e o valor
de intensidade de um pixel $p$ da imagem $A$ para $q$ na imagem
$B$, como pode ser visto pela Equação \ref{eq:fundamentation:image_registration:transform_eq}.
Figura\ref{fig:fundamentation:image_registration:mapping} mostra
o efeito desse mapeamento. 

\begin{equation}
T:p\rightarrow q\Leftrightarrow T(p)=q\label{eq:fundamentation:image_registration:transform_eq}
\end{equation}


\begin{figure}[h]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/mapping}
\par\end{centering}

\caption{Registro de imagens é a tarefa de achar uma transformação espacial
de uma imagem em outra. \label{fig:fundamentation:image_registration:mapping}}



\fonte{\cite{ibanez2003itk}}
\end{figure}


Na literatura, é possível encontrar diversas definições para o problema
de registro de imagens. De acordo com \cite{brown1992survey}, o processo
de registro de imagens é transformação de conjuntos distintos de dados
para um mesmo sistema de coordenadas. Em \cite{crum2014non} é definido
como um processo que determina correspondências entre as características
de imagens extraídas em diferentes momentos, pontos de vista ou aparelhos.
Tais correspondências podem ser utilizadas para aplicar transformações
(rotação, translação, alongamento, etc.) em uma das imagens, de forma
que seja possível a comparação entre as duas. A forma mais intuitiva
de utilização do registro é para corrigir diferenças na posição entre
varreduras . O registro de imagens adiciona valor à imagens, permitindo
que imagens estruturais (CT, MR, ultrasom) e funcionais (PET, SPECT,
functional MRI) sejam vistas e analisadas no mesmo sistema de coordenadas,
e facilita o uso de novas imagens, como para monitorar e quantificar
a evolução de uma doença à medida que o tempo passa \cite{crum2014non}.

A Figura \ref{fig:fluxo-registro} mostra o fluxograma básico de um
processo de registro de imagens. O conjunto de entrada básico de um
processo de registro de imagens é composto por:
\begin{itemize}
\item Imagem fixa: imagem estática cujo espaço de coordenadas é o objetivo.
\item Imagem móvel: imagem que será transformada para o espaço de coordenadas
da imagem fixa.
\item Transformação: função que irá ser responsável por mapear os pixels
da imagem móvel na imagem fixa. Geralmente é responsável por dar nome
ao registro.
\item Métrica: uma medida que indica o quanto duas imagens são equivalentes.
\item Interpolador: uma técnica para interpolar os valores da imagem móvel
quando são remostrados através da transformação.
\item Otimizador: o método utilizador para achar os melhores parâmetros
da transformação que otimizam a métrica entres as duas imagens. 
\end{itemize}
\begin{figure}[h]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/fluxo}
\par\end{centering}

\begin{centering}
\caption{Fluxograma do processo de registro de imagens. \label{fig:fluxo-registro}}

\par\end{centering}


\fonte{\cite{parraga2008atlas}}
\end{figure}



\subsection{Métricas de similaridade}

As métricas de similaridade são provavelmente o elemento mais crítico
no problema do registro de imagens, pois define o objetivo final do
processo que é medir o quanto a imagem móvel é equivalente à imagem
fixa após a transformação ser aplicada. 


\subsubsection{Correlação Cruzada Normalizada\label{sec:fundamentation:image_registration:metric:ccn}}

A Correlação Cruzada Normalizada é uma métrica insensível à fatores
multiplicativos entre as imagens. Produz uma função de custo com picos
afiados e mínimos bem definidos. Por outro lado tem um raio de captura
relativamente pequeno. Sua aplicação é limitada a imagens de mesma
modalidade (adquiridas com o mesmo tipo de aparelho) \cite{ibanez2003itk}.
A correlação cruzada normalizada é dada pela Equação \ref{eq:fundamentation:image_registration:normalized_cross_correlation}:

\begin{equation}
C(f,m)=-1\cdot\frac{\sum_{i=1}^{N}(f_{i}\cdot m_{i})}{\sqrt{\sum_{i=1}^{N}f_{i}^{2}\cdot}\sum_{i=1}^{N}m_{i}^{2}},\label{eq:fundamentation:image_registration:normalized_cross_correlation}
\end{equation}
onde $f$ e $m$ são os valores de pixels em forma de vetor das imagens
fixa e móvel, respectivamente, $i$ indica a posição do pixel em $f$
e $m$, $N$ é a quantidade pixels a ser considerado. Note que o a
equação é multiplicada por $-1$. Esse fator é responsável por fazer
o otimizador procurar os valores que mais se aproximem de $0$, que
é quando duas imagens são ditas equivalentes.


\subsection{Transformação}

A transformação é responsável por mapear os pixels da imagem móvel
para a imagem fixa. Podemos dividir as transformações em dois conjuntos
distintos, rígidas e deformáveis. 

As transformações rígidas aplicam sobre a imagem móvel apenas transformações
simples como operações de translação e rotação, dessa forma a imagem
móvel não sofre deformações, sofrendo apenas o alinhamento de suas
coordenadas. Registros que utilizam transformações rígidas são chamados
de registro rígidos e na prática não são utilizados individualmente,
pois não são capazes de corrigir erros locais que necessitam de transformações
mais complexas para serem resolvidas. Apesar disso, são bastante utilizados
como pré-processamento para os chamados registros deformáveis. 

As transformações deformáveis são capazes de efetuar deformações nas
imagens, dessa forma é possível corrigir erros que uma transformação
rígida não é capaz de corrigir. Registro de imagens que utilizam esse
tipo de transformação são geralmente chamados de registros não-rígidos
ou deformáveis. 


\subsubsection{Translação}

A translação é uma transformação rígida bastante simples. Ela mapeia
todos os pontos da imagem móvel adicionando um vetor à eles. Dado
um ponto 2D $p=(x,y)$, e o vetor de translação $\vec{t}=(t_{x},t_{y})$,
podemos dizer que o ponto transladado $q$ é dado por 

\begin{equation}
q=p+\vec{t}=(x+t_{x},y+t_{y}).\label{eq:fundamentation:image_registration:transform:translate}
\end{equation}


Utilizando a notação de matrizes em coordenadas homogêneas temos

\begin{equation}
q=\begin{bmatrix}x'\\
y'\\
1
\end{bmatrix}=\begin{bmatrix}1 & 0 & t_{x}\\
0 & 1 & t_{y}\\
0 & 0 & 1
\end{bmatrix}\cdot\begin{bmatrix}x\\
y\\
1
\end{bmatrix}.\label{eq:fundamentation:image_registration:transform:translate_matrix}
\end{equation}


A Figura \ref{fig:fundamentation:image_registration:transform:translate}
demonstra o resultado da transformação de translação. Vemos que apenas
as posições dos pixels foram alteradas.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/translate}
\par\end{centering}

\caption{Efeito da translação.\label{fig:fundamentation:image_registration:transform:translate}}



\fonte{Elaborada pelo autor}
\end{figure}



\subsubsection{Rotação}

A rotação é uma transformação rígida capaz de rotacionar os objetos
em relação a um determinado ponto. Dado um ponto $p=(x,y)$ e um ângulo
de rotação $\theta$ em radianos, o ponto $q$ é o resultado da rotação
de $p$ em $\theta$ radianos dado por

\begin{equation}
q=\begin{bmatrix}x'\\
y'\\
1
\end{bmatrix}=\begin{bmatrix}cos\,\theta & -sen\,\theta & 0\\
sen\,\theta & cos\,\theta & 0\\
0 & 0 & 1
\end{bmatrix}.\label{eq:fundamentation:image_registration:transform:rotation}
\end{equation}


A Figura \ref{fig:fundamentation:image_registration:transform:rotation}
representa uma transformação de 90º em torno da origem dos eixos.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/rotation}
\par\end{centering}

\caption{Rotação de $\theta=\frac{\pi}{2}=90\text{º}.$\label{fig:fundamentation:image_registration:transform:rotation}}



\fonte{Elaborada pelo autor}
\end{figure}


Geralmente em registro de imagens, a translação e rotação são aplicadas
em conjunto, para que a rotação não altere a posição do objeto. Dessa
forma, aplicamos uma operação de translação para trazer o objeto para
a origem das coordenadas, aplicamos a rotação, então aplicamos uma
translação inversa para levar o objeto de volta para sua posição inicial.


\subsubsection{Escala}

A transformação de escala é uma transformação não-rígida capaz alterar
a forma de um objeto. Dado um ponto $p=(x,y)$ e o fator de escala
$s=(s_{x},s_{y})$, podemos dizer que o ponto $q$ é dado por 

\begin{equation}
q=p\cdot s=(x\cdot s_{x},y\cdot s_{y}).\label{eq:fundamentation:image_registration:transform:scale}
\end{equation}


Em notação de matrizes homogêneas temos

\begin{equation}
q=\begin{bmatrix}x'\\
y'\\
1
\end{bmatrix}=\begin{bmatrix}s_{x} & 0 & 0\\
0 & s_{y} & 0\\
0 & 0 & 1
\end{bmatrix}\cdot\begin{bmatrix}x\\
y\\
1
\end{bmatrix}.\label{eq:fundamentation:image_registration:transform:scale_matrix}
\end{equation}


Na Figura \ref{fig:fundamentation:image_registration:transform:scale}
vemos o efeito da transformação de escala. Caso os parâmetros sejam
iguais $s_{x}=s_{y}$, não mudamos a forma do objeto. Porém, caso
$s_{x}\neq s_{y}$, temos uma transformação que altera a forma do
objeto transformado.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/scale}
\par\end{centering}

\caption{Transformação de escala.\label{fig:fundamentation:image_registration:transform:scale}}



\fonte{Elaborada pelo autor}
\end{figure}



\subsubsection{Transformações FFD baseadas em \emph{B-Splines }cúbicas \label{sec:fundamentation:image_registration:transform:bspline}}

Um dos tipos de transformações não-rígidas mais comuns atualmente
são as chamadas transformações FFD (deformação de forma livre) baseadas
em \emph{B-splines} cúbicas \cite{yin2009mass}. A ideia básica desse
tipo de transformação é manipular a grade de pixels a partir dos chamados
pontos de controle. Essa manipulação permite criar um campo de deslocamento,
que irá mapear os pixels da imagem móvel. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/displacement}
\par\end{centering}

\caption{O conceito de campo de deslocamento. Para cada posição de pixel na
imagem móvel, existe uma direção e distância que ele precisa se mover
para se assemelhar à imagem fixa. }



\fonte{\cite{schwarz2007non}}
\end{figure}


Seja $\Phi$ a grade uniforme de dimensões $n_{x}\times n_{y}\times n_{z}$
com $\Phi_{i,j,k}$ representando o deslocamento do $ijk$-ésimo ponto
de controle. O espaço entre as grandes de controle nas direções $x$,
$y$ e $z$ são denotadas por $\delta_{x}$, $\delta_{y}$e $\delta_{z}$,
respectivamente. A transformação $T(\text{{x}}:\Phi)$ é definida
por 

\begin{equation}
T(\text{{x}}:\Phi)=\sum_{l=0}^{3}\sum_{m=0}^{3}\sum_{n=0}^{3}\beta_{l}(u)\beta_{m}(v)\beta_{n}(w)\Phi_{i+l,j+m,k+n},\label{eq:fundamentation:image_registration:ffd_bspline:transform}
\end{equation}
onde os parâmetros são dados por

\begin{equation}
i=|\frac{x}{\delta_{x}}|-1,\label{eq:fundamentation:image_registration:ffd_bspline:p1}
\end{equation}


\begin{equation}
j=|\frac{y}{\delta_{y}}|-1,\label{eq:fundamentation:image_registration:ffd_bspline:p2}
\end{equation}


\begin{equation}
z=|\frac{z}{\delta_{z}}|-1,\label{eq:fundamentation:image_registration:ffd_bspline:p3}
\end{equation}


\begin{equation}
u=\frac{x}{\delta_{x}}-(i+1),\label{eq:fundamentation:image_registration:ffd_bspline:p4}
\end{equation}


\begin{equation}
v=\frac{y}{\delta_{y}}-(j+1),\label{eq:fundamentation:image_registration:ffd_bspline:p5}
\end{equation}


\begin{equation}
w=\frac{z}{\delta_{z}}-(z+1).\label{eq:fundamentation:image_registration:ffd_bspline:p6}
\end{equation}
As funções $\beta$ são \emph{B-splines }cúbicas e definidas por

\begin{equation}
\beta_{0}(t)=(-t^{3}+3t^{2}-3t+1)/6,\label{eq:fundamentation:image_registration:ffd_bspline:b0}
\end{equation}


\begin{equation}
\beta_{1}(t)=(3t^{3}-6t^{2}+4)/6,\label{eq:fundamentation:image_registration:ffd_bspline:b1}
\end{equation}


\begin{equation}
\beta_{2}(t)=(-3t^{3}+3t^{2}+3t+1)/6,\label{eq:fundamentation:image_registration:ffd_bspline:b2}
\end{equation}


\begin{equation}
\beta_{3}(t)=t^{3}/6,\label{eq:fundamentation:image_registration:ffd_bspline:b3}
\end{equation}
onde $0\le t\le1$. 

Um parâmetro muito importante desse tipo de transformação é a resolução
da grade de controle, pois a partir dela serão gerados os campos de
deslocamentos. Uma grade muito espaçosa permite a modelagem de transformações
deformáveis globais, enquanto uma grade mais fina modela deformações
altamente locais \cite{yin2009mass}.


\subsection{Interpolador}

No processo do registro, a métrica geralmente compara os valores de
intensidade dos pixels da imagem fixa com os pixels correspondentes
na imagem móvel transformada. Quando transformamos um ponto de um
espaço para o outro através de uma transformação, este geralmente
irá ser mapeado para uma posição fora da grade de pixels da imagem
(Figura \ref{fig:fundamentation:image_registration:grid}) . A função
do interpolador é calcular o valor de intensidade em uma dada posição
de forma correta \cite{ibanez2003itk}.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/image_registration/ITKSoftwareGuide-Book2259x}
\par\end{centering}

\caption{Posições de grade da imagem fixa mapeadas para posições fora da grade
na imagem móvel.\label{fig:fundamentation:image_registration:grid}}



\fonte{\cite{ibanez2003itk}}
\end{figure}



\subsubsection{Interpolador Linear\label{sec:fundamentation:image_registration:interpolator:linear}}

O interpolador linear assume que os valores de intensidade dos pixels
variam de forma linear entre as posições de grade. Dessa forma, os
valores interpolados serão contínuos espacialmente, porém o gradiente
de intensidade será descontinuo na grade. Se dois pontos conhecidos
são dados por $(x_{0},y_{0})$ e $(x_{1},y_{1})$ a interpolação linear
é dada pela Equação \ref{eq:fundamentation:image_registration:linear_interpolation}.

\begin{equation}
y=y_{0}+(y_{1}-y_{0})\frac{x-x_{0}}{x_{1}-x_{0}}\label{eq:fundamentation:image_registration:linear_interpolation}
\end{equation}



\subsection{Otimizador}

Como dito anteriormente, o papel do otimizador é encontrar os melhores
parâmetros para a transformação escolhida no processo de registro
de imagens. Dessa forma, um amplo conjunto de otimizadores podem ser
utilizados, como os \emph{Algoritmos Genéticos \cite{whitley1994genetic}
}e o \emph{Gradiente Descendente} \cite{burges2005learning}.


\subsubsection{LBFGS\label{sec:fundamentation:image_registration:otimizator:lbfgs}}

O \emph{LBFGS }(Limited-memory Broyden-Fletcher-Goldfarb-Shanno) é
um método de otimização bastante comum em problemas de registro de
imagens. De acordo com \cite{sheppard2008optimization}, é um método
quasi-Newton que constrói informações sobre as segundas derivadas
durante a otimização e utiliza essa informação para avançar em direção
ao minimo harmônico previsto. Mais especificamente, a inversa da matriz
hessiana $H^{-1}$ é construída interativamente, começando a partir
da matriz diagonal. O método pode ser utilizado de duas formas. Na
primeira, uma direção de busca,

\begin{equation}
d_{j}=F_{j}H_{j}^{-1},\label{eq:fundamentation:image_registration:optimizator:lbfgs:first:dir}
\end{equation}
é identificada em cada iteração, e a minimizador de linha é utilizado
para avançar na direção,

\begin{equation}
R_{j+1}=R_{j}+\lambda d_{j}.\label{eq:fundamentation:image_registration:optimizator:lbfgs:first:dir2}
\end{equation}


A segunda forma é utilizar $H^{-1}$ diretamente para calcular o avanço,

\begin{equation}
R_{j+1}=R_{j}+F_{j}H^{-1}.\label{eq:fundamentation:image_registration:optimizator:lbfgs:first:dir3}
\end{equation}


O LBFGS utiliza a memória da iteração anterior para construir $H^{-1}$.
O número de iterações é um parâmetro variável e é definido pelo usuário.


\section{Matrizes de Coocorrência de Níveis de Cinza\label{sec:fundamentation:glcm}}

A análise de textura em imagens é uma técnica importante na identificação
de características em imagens digitais. Uma das primeiras técnicas
utilizadas para a extração dessas características foram as matrizes
de coocorrências de níveis de cinza também chamadas de \emph{GLCMs
}(Gray Level Co-ocurrence Matrix) originalmente propostas em \cite{haralick1973textural}.
Desde então elas vem sendo bastante utilizadas em várias aplicações
de análise de textura e permanecem sendo uma ferramenta importante
no domínio de análise de texturas \cite{sebastian2012gray}.

A GLCM é uma técnica utilizada para extrair características estatísticas
de textura de segunda ordem \cite{albregtsen2008statistical}, ou
seja, a medição considera a relação entre pares de pixels, geralmente
vizinhos \cite{glcm_tutorial}. 


\subsection{Construção de uma GLCM}

Seja $I$ uma imagem em níveis de cinza e $N$ a quantidade de níveis
de cinza, uma GLCM $G$ é uma matriz quadrada de ordem $N$ \cite{sebastian2012gray}.
O elemento da matriz $P(i,j|\Delta x,\Delta y)$ é a frequência relativa
em que dois pixels de intensidade $(i,j)$, separados por uma distância
$(\Delta x,\Delta y)$, são vizinhos. Também é possível dizer que
o elemento $P(i,j|d,\theta)$ contém os valores da probabilidade de
segunda ordem para mudanças entre os níveis de cinza $i$ e $j$ em
uma distância $d$ e um ângulo $\theta$ \cite{albregtsen2008statistical}.

Seja $I$ uma imagem de dimensões $WxH$, então uma GLCM de $I$ é
definida pela Equação \ref{eq:glcm:def}.

\begin{equation}
G(i,j|\Delta x,\Delta y)=\sum_{p=1}^{W}\sum_{q=1}^{H}A\label{eq:glcm:def}
\end{equation}


\begin{equation}
A=\begin{cases}
1,\:se\:I(p,q)=i\:e\:I(p+\Delta x,q+\Delta y)=j\\
0,\:caso\:contr\acute{a}rio
\end{cases}\label{eq:glcm:case}
\end{equation}


Como exemplo temos uma imagem $I$ de dimensões $5x5$, com $4$ níveis
de cinza. Então as matriz de coocorrência $G(i,j|\Delta x=1,\Delta y=0)$
e $G(i,j|\Delta x=1,\Delta y=1)$ são representadas abaixo.

\[
I=\begin{bmatrix}2 & 0 & 2 & 1 & 1\\
2 & 1 & 2 & 3 & 1\\
3 & 1 & 3 & 2 & 0\\
0 & 0 & 1 & 2 & 2\\
3 & 3 & 3 & 1 & 1
\end{bmatrix}
\]


\[
G(i,j|\Delta x=1,\Delta y=0)=\begin{bmatrix}1 & 1 & 1 & 0\\
0 & 2 & 2 & 1\\
2 & 2 & 1 & 1\\
0 & 3 & 1 & 2
\end{bmatrix}
\]


\[
G(i,j|\Delta x=1,\Delta y=1)=\begin{bmatrix}0 & 0 & 1 & 2\\
0 & 3 & 0 & 1\\
0 & 3 & 2 & 1\\
2 & 0 & 1 & 0
\end{bmatrix}
\]



\subsection{GLCM Normalizada}

Considere $N=\sum_{i}\sum_{j}G_{d}(i,j)$, que é a quantidade ocorrências
de pares em $G_{d}$. Seja $GN_{d}(i,j)=\frac{1}{N}G_{d}(i,j)\cdot GN_{d}$,
chamada de GLCM normalizada, onde as entradas $(i,j)$ de $GN_{d}(i,j)$
são as probabilidades de coocorrência de um determinado pixel com
intensidade $i$ ser separado de um pixel de intensidade $j$ por
uma distância $k$ em uma determinada direção $d$ \cite{sebastian2012gray}.


\subsection{Características de Textura}

A partir de uma GLCM, é possível extrair um conjunto de características
que descrevem a textura de determinada imagem \cite{albregtsen2008statistical},
disponíveis em \cite{haralick1973textural,haralick1979statistical,conners1984segmentation}.
De acordo com \cite{glcm_tutorial} temos as seguintes características
que podem ser extraídas a partir de uma GLCM:

\begin{equation}
Constraste=\sum_{i,j=0}^{N-1}P_{i,j}(i-j)^{2}\label{eq:fundamentation:glcm:contraste}
\end{equation}


\begin{equation}
Dissimilaridade=\sum_{i,j=0}^{N-1}P_{i,j}|i-j|\label{eq:fundamentation:glcm:dissimilaridade}
\end{equation}


\begin{equation}
Homogeineidade=\sum_{i,j=0}^{N-1}\frac{P_{i,j}}{1+(i-j)^{2}}\label{eq:fundamentation:glcm:homogeneidade}
\end{equation}


\begin{equation}
ASM=\sum_{i,j=0}^{N-1}P_{i,j}^{2}\label{eq:fundamentation:glcm:asm}
\end{equation}


\begin{equation}
Energia=\sqrt{ASM}\label{eq:fundamentationg:glcm:energia}
\end{equation}


\begin{equation}
Correla\cedilla{c}\tilde{a}o=\sum_{i,j=0}^{N-1}P_{i,j}\left[\frac{(i-\mu_{i})\cdot(j-\mu_{j})}{\sqrt{(\sigma_{i}^{2})\cdot(\sigma_{j}^{2})}}\right]\label{eq:fundamentationg:glcm:correla=0000E7=0000E3o}
\end{equation}


\begin{equation}
\mu_{i}=\sum_{i,j=0}^{N-1}i\cdot(P_{i,j})\label{eq:fundamentationg:glcm:media_i}
\end{equation}


\begin{equation}
\mu_{j}=\sum_{i,j=0}^{N-1}j\cdot(P_{i,j})\label{eq:fundamentationg:glcm:media_j}
\end{equation}


\begin{equation}
\sigma_{i}^{2}=\sum_{i,j=0}^{N-1}P_{i,j}(i-\mu_{i})^{2}\label{eq:fundamentationg:glcm:variantion_i}
\end{equation}


\begin{equation}
\sigma_{j}^{2}=\sum_{i,j=0}^{N-1}P_{i,j}(j-\mu_{j})^{2}\label{eq:fundamentationg:lcm:variation_j}
\end{equation}


onde $N$ é quantidade de níveis de cinza $P_{i,j}$é a frequência
de um par de pixels $i$ e $j$ serem vizinhos. 


\section{Redução de Dimensionalidade\label{sec:fundamentation:dimensionality_reduction}}

Em \emph{Aprendizado de Máquina}, geralmente possuímos um conjunto
de dados previamente disponíveis . Nesse conjunto de dados, cada indivíduo
é representado por um conjunto de características extraídas do dado
original. Por exemplo, em imagens de níveis de cinza é possível extrair
as características a partir de uma GLCM. A quantidade de características
que um indivíduo possui é o que chamamos de \emph{dimensão}. Para
um conjunto de dados de dimensão $D=6$, então temos $6$ características
que descrevem cada indivíduo. 

A fácil pensar que quanto maior o número de características, melhor
para discriminar os indivíduos. Porém, um conjunto de dados com uma
dimensão muito alta implica maior complexidade no problema de classificação.
Outro problema é que, em muitos casos, nem todas as características
são consideradas importantes para o entendimento de um certo problema\cite{fodor2002survey}.

Em termos matemáticos, o problema de \emph{Redução de Dimensionalidade}
pode ser descrito da seguinte forma: Dado um conjunto dados com $p$
dimensões $x=(x_{1},x_{2},...,x_{p})^{T}$, encontrar uma representação
de menor dimensão $s=(s_{1},s_{2},...,s_{k})^{T}$, onde $k\le p$
, que seja capaz de capturar o conteúdo dos dados originais, de acordo
com um critério preestabelecido \cite{fodor2002survey}.

Algumas técnicas de redução de dimensionalidade são descritas abaixo\emph{.}


\subsection{Seleção de Características Univariada}

A seleção de características univariada seleciona as melhores características
baseada em testes estatísticos univariados \cite{scikit-learn-feat}.
Por exemplo, podemos selecionar as $K$ melhores características através
de um teste estatístico que classifique as características que melhor
separam as classes de indivíduos de um conjunto de dados. 


\subsection{Análise de Componentes Principais}

A Análise de Componentes Principais\emph{ }(PCA) é uma técnica de
redução linear \cite{jackson2005user}. Por ser baseada na matriz
de covariância dos dados, é um método de segunda ordem. O PCA reduz
a dimensionalidade encontrando os \emph{principais componentes }(PCs)
do conjunto de dados com maior variância, que são vetores formados
pelas combinações das características originais. Por exemplo, o primeiro
PC é o que possui maior variância, Temos $s_{1}=x^{T}w_{1}$, onde
o vetor de coeficientes de $p$ dimensões é $w_{1}=(w_{1,1},...,w_{1,p})^{T}$
que resolve: 

\begin{equation}
w_{1}=arg\:max_{||w=1||}Var\{x^{T}w\}\label{eq:fundamentation:reduction:pca}
\end{equation}


O segundo PC é a combinação linear com a segunda maior variância e
ortogonal ao primeiro PC, e assim sucessivamente. Existem tantos PCs
quanto o número de características originais \cite{fodor2002survey}. 

Geralmente, normaliza-se os dados antes da aplicação do PCA, pois
o método é dependente da escala. Um dos métodos possíveis para a normalização
é escalar cada características entre 0 e 1. Então, assumindo que os
dados estão normalizados, podemos calcular a matriz de covariância

\begin{equation}
C=\frac{1}{p-1}\sum_{i=1}^{p}(x_{i}-\bar{x})\cdot(x_{i}-\bar{x})^{T},\label{eq:fundamentation:reduction:pca:cov}
\end{equation}
onde $\bar{x}$é o vetor médio dado por

\begin{equation}
\bar{x}=\frac{1}{p}\sum_{i=1}^{p}x_{i}.\label{eq:fundamentation:reduction:pca:mean_vector}
\end{equation}


Utilizando a relação

\begin{equation}
Cv=\lambda v,\label{eq:fundamentation:reduction:pca:eigen}
\end{equation}


onde $v$ é um autovetor de $C$ e $\lambda$o seu respectivo autovalor.
Cada autovetor corresponde a um PC, e os respectivos autovalores indicam
o grau de variância de cada PC. Assim, escolhendo os $k$ PCs com
maior variância absoluta, podemos mapear nossos dados originais em
um novo conjunto 

\begin{equation}
S=W^{T}X,\label{eq:fundamentation:reduction:pca:result}
\end{equation}
onde $X$ é o conjunto de dados originais e $W$ uma matriz de transformação

\begin{equation}
W=(v_{1},...v_{k}),\label{eq:fundamentation:reduction:pca:transform}
\end{equation}
onde $v_{1}$é o PC de maior variância e $v_{k}$ o k-ésimo PC de
maior variância.

É uma técnica muito útil quando queremos transformar nossas características
originais, onde alguma delas não oferecem muita variação nos dados,
em um espaço novo com menor dimensão onde as novas características
possuem uma melhor dispersão nos dados. A Figura \ref{fig:fundamentation:reduction:pca:samples}
mostra um conjunto de indivíduos gerados por distribuições normais
multivariadas com 3 características. Utilizando o PCA para reduzir
o espaço dimensional para apenas 2, temos a Figura \ref{fig:fundamentation:reduction:pca:samples_transformed},
que exemplifica o efeito da redução. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/dimensionality_reduction/pca_samples}
\par\end{centering}

\caption{Amostras geradas utilizando um distribuição normal multivariada.\label{fig:fundamentation:reduction:pca:samples}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/dimensionality_reduction/pca_samples_transformd}
\par\end{centering}

\caption{Amostras reduzidas para o espaço bidimensional utilizando os dois
principais componentes.\label{fig:fundamentation:reduction:pca:samples_transformed}}



\fonte{Elaborada pelo autor}
\end{figure}



\subsection{Análise Discriminante Linear}

A Análise Discriminante Linear (LDA) é uma técnica similar ao PCA,
onde buscamos combinações lineares da características para formar
um novo espaço de dimensões reduzidas. A diferença é que ao contrário
do PCA que busca combinações com maior variância entre os dados, o
LDA procura combinações que melhor separam as classes de um determinado
problema, portanto podemos dizer que o LDA é uma técnica supervisionada,
pois precisamos conhecer as classes que cada individuo pertence.

Normalmente é utilizado para redução de dimensionalidade, como um
pré-processamento de técnicas de aprendizado de máquina e reconhecimento
de padrões\cite{raschkaLDA}. Também é possível utilizar o LDA como
um classificador. Originalmente proposto em \cite{fisher1936use}como
um problema \emph{2-class}, que foi generalizado para um problema
\emph{multi-class }em \cite{rao1948utilization}.

Considerando um conjunto de observações $X$ de dimensões $k\times p$,
em que $k$ corresponde à quantidade de indivíduos e $p$ à quantidade
de características de cada indivíduo. Para cada indivíduo em $X$,
existe um elemento em $y$ que indica a classe ao qual pertence. O
objetivo é encontrar uma transformação $W$, que maximize a distância
entre classes (Figura \ref{fig:fundamentation:reduction:lda:bc})
e minimize a distância intra-classe (Figura \ref{fig:fundamentation:reduction:lda:wc}). 

\begin{figure}
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/dimensionality_reduction/wc}
\par\end{centering}

\caption{Distância intra-classe.\label{fig:fundamentation:reduction:lda:wc}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.45]{figures/fundamentation/dimensionality_reduction/bc}\caption{Distancia inter-classes. \label{fig:fundamentation:reduction:lda:bc}}

\par\end{centering}


\fonte{Elaborada pelo autor}
\end{figure}


Dessa forma$W$ mapeia $X$ em $\bar{X}$ através da Equação \ref{eq:fundamentation:reduction:lda:map}

\begin{equation}
\bar{X}=W^{T}\cdot X\label{eq:fundamentation:reduction:lda:map}
\end{equation}
onde $W$ é formado pelos $m$ autovetores com maiores autovalores
absolutos da matriz $S$ dada pela Equação \ref{eq:fundamentation:reduction:lda:sigma}
. Uma observação importante é que $m<c-1$, onde $c$ é a quantidade
de classes que existem em $y$ \cite{raschkaLDA}. 

\begin{equation}
S=S_{W}^{-1}\cdot S_{B}\label{eq:fundamentation:reduction:lda:sigma}
\end{equation}


A matriz $S_{W}$ é o que chamamos de matriz de dispersão intra-classe
e é definida por:

\begin{equation}
S_{W}=\sum_{i=1}^{c}S_{i}\label{eq:fundamentation:reduction:lda:wc}
\end{equation}


\begin{equation}
S_{i}=\sum_{x\in c_{i}}^{n}(x-\mu_{i})\cdot(x-\mu_{i})^{T}\label{eq:fundamentation:reduction:lda:scatter_every_class}
\end{equation}


\begin{equation}
\mu_{i}=\frac{1}{n_{i}}\sum_{x\in c_{i}}^{n}x_{k}\label{eq:fundamentation:reduction:lda:mean_vector_class}
\end{equation}
onde, $S_{i}$ é matriz de dispersão da classe $c_{i}$ e $\mu_{i}$
é o vetor que representa os valores médios de cada característica
de indivíduos que pertencem a classe $c_{i}$.

A matriz $S_{B}$ é chamada de matriz de dispersão inter-classes e
é definida por:

\begin{equation}
S_{B}=\sum_{i=1}^{c}N_{i}(\mu_{i}-\mu)\cdot(\mu_{i}-\mu)^{T}\label{eq:fundamentation:reduction:lda:bc}
\end{equation}
onde, $N_{i}$ é a quantidade de indivíduos que pertencem a classe
$c_{i}$ e $\mu$é o vetor que representa a média das características
de todos os indivíduos em $X$. 

A vantagem de utilizar o LDA é que simplificamos o problema de classificação
criando novas características, a partir das originais, que melhor
separam as classes do conjunto de dados. A grande desvantagem é que
não é possível saber quais características originais tem maior peso,
pois os discriminantes são formados a partir de combinações lineares
de todas elas. A Figura \ref{fig:fundamentation:reduction:lda:samples}
apresenta um conjunto de indivíduos que pertencem a três classes distintas.
Cada classe foi gerada a partir de uma distribuição normal multivariada,
onde os parâmetros diferem entre elas. A Figura \ref{fig:fundamentation:reduction:lda:samples_transformed}
apresenta o resultado da aplicação do LDA para efetuar a redução do
espaço tridimensional para bidimensional.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/dimensionality_reduction/lda_samples}\caption{Amostras geradas de distribuções normais multivariadas.\label{fig:fundamentation:reduction:lda:samples}}

\par\end{centering}


\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/dimensionality_reduction/lda_samples_transformed}
\par\end{centering}

\caption{Resultado da aplicação do LDA para reduzir as amostras da Figura \ref{fig:fundamentation:reduction:lda:samples}.
\label{fig:fundamentation:reduction:lda:samples_transformed}}



\fonte{Elaborada pelo autor}
\end{figure}



\section{Máquinas de Vetor de Suporte}

Problemas de classificação geralmente envolvem classificar se um certo
indivíduo pertence à classe $A$,$B$ ou $C$. Atualmente existem
diversas técnicas de aprendizado de máquina capazes de realizar essa
tarefa com êxito e umas das principais técnicas utilizadas hoje em
dia são as Máquinas de Vetor de Suporte (SVM). Foram originalmente
propostas por \cite{cortes1995support} como uma classificador binário,
capaz de dizer se um determinado indivíduo pertence à classe $A$
ou $B$. São parte do grupo de técnicas de aprendizado supervisionado,
onde é necessário conhecer previamente um conjunto de indivíduos para
que o algoritmo gere um modelo que seja capaz de predizer qual a classe
uma nova entrada pertence.

Uma SVM constrói hiperplanos em um espaço de alta dimensão, que pode
ser utilizado para a tarefa de classificação. Uma boa separação é
obtida através do hiperplano que possui maior distância entre os pontos
mais próximos de cada classe no conjunto de dados de treino \cite{sklearn-svm}. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/fundamentation/svm/plot_separating_hyperplane}
\par\end{centering}

\caption{Construção de hiperplanos.\label{fig:fundamentation:svm:hiperplanos}}



\fonte{\cite{sklearn-svm}}
\end{figure}


De acordo com \cite{giovannitcc}, dado $(x_{k},y_{k})$ o conjunto
de amostras para treinamento, sendo que $x_{i}\in\mathbb{R}^{n}$
correspondente ao vetor de características do indivíduo $i$, $y_{i}\in\{1,-1\}$
corresponde à classe do indivíduo $i$, sendo $i=1,2,...,k$. O objetivo
do problema de classificação é encontrar uma função $f(x):\mathbb{R}^{n}\rightarrow\{1,-1\}$
que seja capaz de estimar corretamente a classe do indivíduo $x$.

Na etapa de treinamento a função $f(x)=(w\cdot x)+b$ é estimada,
de forma que a seguinte relação seja satisfeita:

\begin{equation}
y_{i}((w\cdot x_{i})+b)\ge1\label{eq:fundamentation:svm:relation}
\end{equation}
onde $w$ é o vetor normal ao hiperplano e $b$ a distância da função
$f$ em relação à origem. Os valores ótimos de $w$ e $b$ são encontrados
de acordo com a restrição dada pela Equação \ref{eq:fundamentation:svm:relation}
ao minimizar a equação:
\begin{equation}
\phi(w)=\frac{w^{2}}{2}\label{eq:fundamentation:svm:min}
\end{equation}


O SVM possibilita encontrar um hiperplano que minimize a ocorrência
de erros nos casos em que a separação ótima entre as classes não seja
possível. Com a utilização de variáveis de folga, é possível relaxar
a restrição da Equação \ref{eq:fundamentation:svm:relation}. Dessa
forma o SVM resolve problema de otimização:

\begin{equation}
min\:\phi(w,\zeta)=\frac{w^{2}}{2}C\sum_{i=1}^{N}\zeta_{i}\label{eq:fundamentation:svm:problem}
\end{equation}
sujeito à:

\begin{equation}
y_{i}((w\cdot x_{i})+b)+\zeta_{i}\ge1\label{eq:fundamentation:svm:relaxed}
\end{equation}
onde $C$ é um parâmetro de treinamento que define o equilíbrio entre
a complexidade do modelo e o erro de treinamento.

Utilizando a teoria do multiplicadores de Lagrange é possível obter:

\begin{equation}
L(a)=\sum_{i=1}^{N}a_{i}-\frac{1}{2}\sum_{i,j=1}^{N}a_{i}a_{j}y_{i}y_{j}(x_{i},x_{j})\label{eq:fundamentation:svm:lagrange}
\end{equation}


Assim, o objetivo passar a ser encontrar os multiplicadores de Lagrange
$a_{i}$ ótimos que satisfação a Equação \ref{eq:fundamentation:svm:lagrange2}
\cite{chaves2006extraccao}.

\begin{equation}
\sum_{i=1}^{N}a_{i}y_{i}=0,\:0\le a_{i}\le C\label{eq:fundamentation:svm:lagrange2}
\end{equation}


Apenas os pontos onde a restrição imposta pela Equação \ref{eq:fundamentation:svm:relation}
é igual$1$, tem correspondentes $a_{i}\neq0$. Esses pontos são chamados
de vetores de suporte, e estão geometricamente sobre as margens, possuindo
grande importância na definição do hiperplano ótimo, pois delimitam
as margens do conjunto de treinamento. Na Figura \ref{fig:fundamentation:svm:vetores},
os vetores de suporte são representados por círculos circunscritos.

\begin{figure}
\begin{centering}
\includegraphics{figures/fundamentation/svm/vetores}
\par\end{centering}

\caption{Vetores de suporte.\label{fig:fundamentation:svm:vetores}}



\fonte{Elaborada pelo autor}
\end{figure}


Pontos além da margem não tem influência suficiente para determinar
o hiperplano, porém esses vetores de suporte são essenciais nessa
tarefa.

Agora considere o conjunto de amostras da Figura \ref{fig:fundamentation:svm:data_nao_linear}.
Vemos que não é possível traçar uma reta capaz de separar as classes,
tornando o problema um caso não-linear. De acordo com \cite{giovannitcc},
necessitamos de uma transformação não-linear capaz de mapear o conjunto
original (espaço dados) para um novo espaço (espaço de características).
Esse novo espaço deve apresentar dimensões suficientes para que seja
possível realizar a separação linear do conjunto de dados. Dessa forma,
o hiperplano de separação é definido como uma função linear de vetores
retirados do espaço de características e não do espaço de dados. A
construção desse conjunto depende de uma função \emph{$K$}, chamada
de \emph{kernel} \cite{haykin2001redes}. A Equação \ref{eq:fundamentation:svm:lagrange3}
apresenta a forma modificada da \ref{eq:fundamentation:svm:lagrange2}
utilizando uma função $K$.

\begin{figure}[H]
\begin{centering}
\includegraphics{figures/fundamentation/svm/nao_linear}
\par\end{centering}

\caption{Conjunto de indivíduos não separáveis linearmente.\label{fig:fundamentation:svm:data_nao_linear}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{equation}
L(a)=\sum_{i=1}^{N}a_{i}-\frac{1}{2}\sum_{i,j=1}^{N}a_{i}a_{j}y_{i}y_{j}K(x_{i},x_{j})\label{eq:fundamentation:svm:lagrange3}
\end{equation}


Um conjunto de funções amplamente utilizadas em conjunto com uma SVM
para classificação de dados não linearmente separáveis sãos as funções
de base radial (RBF). Uma função RBF é definida por:

\begin{equation}
K(x_{i},y_{i})=exp(-\gamma||x_{i}-y_{i}||^{2})\label{eq:fundamentation:svm:rbf}
\end{equation}
onde $\gamma=1/\sigma^{2}$, onde $\sigma$ é a variância.


\chapter{Metodologia \label{sec:metodologia}}

Nesta seção, são apresentados os procedimentos propostos para a realização
dos objetivos descritos na Seção \ref{sec:objectives}. A Figura \ref{fig:metothology:fluxogram}
apresenta o fluxo das etapas executadas. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fluxograma_metodologia}
\par\end{centering}

\begin{centering}
\caption{Fluxograma da metodologia.\label{fig:metothology:fluxogram}}

\par\end{centering}


\fonte{Elaborada pelo autor}
\end{figure}



\section{Aquisição de Imagens}

A aquisição de imagens é uma etapa crucial na metodologia proposta,
pois sem imagens para casos de teste não é possível validar a metodologia.
Atualmente existem poucos bancos de imagem termográficas mamárias
disponíveis para o público geral, sendo a maioria deles de propósito
privado. As imagens utilizadas neste trabalho são provenientes do
\emph{Database for Mastology Research with Infrared Image }- DMR-IR,
acessível através da interface on-line \url{httt://visual.ic.uff.br/dmi}.
Mais informações sobre a base de imagens utilizada podem ser encontradas
em \cite{silvaasmd} e \cite{silva2014new}.

De acordo com \cite{silva2014new}, no protocolo de termografias dinâmicas
as pacientes são submetidas a um estresse térmico causado pela refrigeração
por um ventilador elétrico. Quando a média de temperatura entre as
mamas é de 30.5ºC (Figura \ref{fig:methodology:acquisition:mean_monitoring}),
ou 5 minutos de estresse foram aplicados, a refrigeração é interrompida
e a aquisição sequencial das imagens é iniciada, extraindo um total
de 20 imagens sequenciais com intervalos de tempo fixos.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/protocol_mean}
\par\end{centering}

\begin{centering}
\caption{Monitoramento da temperatura média para começar a aquisição sequencial.\label{fig:methodology:acquisition:mean_monitoring}}

\par\end{centering}


\fonte{\cite{silva2014new}}
\end{figure}


As imagens utilizadas possuem dimensão de 640 pixels de largura e
480 pixels de largura e foram utilizados os valores de temperatura
(em graus celsius) obtidos diretamente da câmera termográfica utilizada
na aquisição. A Figura \ref{fig:methodology:acquisition:matrix} apresenta
essas matrizes são armazenadas em formato \emph{.txt}, onde cada exame
é composto por 20 arquivos separados por tempo de aquisição. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.75]{figures/methodology/temp_matrix}
\par\end{centering}

\begin{centering}
\caption{Matriz de temperatura.\label{fig:methodology:acquisition:matrix}}

\par\end{centering}


\fonte{\cite{lincoln_thesis2015}}
\end{figure}


No total foram utilizados 70 exames previamente diagnosticados para
aplicação desta metodologia, sendo que 35 são de pacientes saudáveis
e os 35 restantes de pacientes que apresentam algum tipo de anomalia
nas mamas.


\section{Registro das Imagens\label{sec:methodology:image_registration}}

Durante o protocolo de aquisição de imagens, é natural que a paciente
execute movimentos involuntários causados pela respiração e ajuste
de postura. Esses movimentos causam diferenças espaciais de uma sequência
para a outra. As Figuras \ref{fig:methodology:image_registration:t1}
e \ref{fig:methodology:image_registration:t2} são termogramas sequências
de tempos $t=1$ e $t=2$, respectivamente. A Figura \ref{fig:methodology:image_registration:squared_diff}
apresenta a diferença quadrática $d=(P_{t}(i,j)-P_{t}(i,j))^{2}$,
onde $(i,j)$ é a posição do pixel, sendo $i=0,...,639$ e $j=0,...,479$,
e $P_{t}(i,j)$ é o valor de pixel na posição $(i,j)$ no tempo $t$.
É possível notar que existe uma diferença causada pela movimentação
involuntária da paciente.

\begin{figure}[H]
\subfloat[\label{fig:methodology:image_registration:t1}]{\begin{centering}
\includegraphics[scale=0.2]{figures/methodology/series1}
\par\end{centering}

}\hfill{}\subfloat[\label{fig:methodology:image_registration:t2}]{\begin{centering}
\includegraphics[scale=0.2]{figures/methodology/series2}
\par\end{centering}

}\hfill{}\subfloat[\label{fig:methodology:image_registration:squared_diff}]{\begin{centering}
\includegraphics[scale=0.2]{figures/methodology/series_diff}
\par\end{centering}

}

\caption{Termogramas de tempos distintos. Tons mais claros denotam uma maior
diferênça entre as regiões. }



\fonte{Elaborada pelo autor.}
\end{figure}


Para analisar as sequências de termogramas de um determinado exame
é necessário corrigir essas diferenças, dessa forma o registro de
imagens é uma etapa essencial de pré-processamento das termografias.
Para a construção do registro, as seguintes técnicas foram utilizadas:


\begin{itemize}
\item Métrica: Correlação Cruzada Normalizada (Seção\ref{eq:fundamentation:image_registration:normalized_cross_correlation})
\item Transformação: \emph{B-Splines} (Seção \ref{sec:fundamentation:image_registration:transform:bspline})
\item Interpolador: Linear (Seção \ref{sec:fundamentation:image_registration:interpolator:linear})
\item Otimizador: LBFGS (Seção \ref{sec:fundamentation:image_registration:otimizator:lbfgs})
\end{itemize}


Utilizando a primeira sequência do conjunto de termograma como imagem
fixa, executamos o algoritmo de registro 19 vezes, sendo que as sequências
restantes são as imagens móveis. A Figura \ref{fig:methodology:registration:result}
demostra a utilização do registro construído, na Figura \ref{fig:methodology:image_registration:t2}
como imagem móvel e tendo a Figura \ref{fig:methodology:image_registration:t1}
como imagem fixa.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/registered_squared_differences1}
\par\end{centering}

\caption{Resultado da aplicação do registro na Figura \ref{fig:methodology:image_registration:t2}
como móvel e a Figura \ref{fig:methodology:image_registration:t1}
como fixa. Note que a diferença de postura foi corrigida, deixando
a imagem majoritariamente escura.\label{fig:methodology:registration:result}}
\end{figure}



\section{Extração da Região de Interesse}

Essa etapa consiste em extrair a região de interesse (ROI) da imagem.
Como a metodologia tem o objetivo de detectar anomalias no padrão
de vascularização das mamas, é de interesse que as demais regiões
de uma TID sejam excluídas do processo. Alguns métodos de segmentação
automática são encontrados na literatura \cite{marques2012segmentaccao},
porém existem limitações que não tornam possíveis a utilização desse
tipo de técnica. Dessa forma, a região de interesse é extraída de
forma manual, através da utilização de um programa de visualização
e edição de imagens. 

Apesar de cada TID possuir um total de 20 sequências de termogramas,
utilizamos apenas a sequência no tempo inicial para gerar uma máscara
responsável por demarcar a ROI segmentada manualmente através do software
ImageJ \cite{abramoff2004image,rasband1997bethesda}. Utilizando a
máscara da sequência inicial é possível extrair as ROIs das demais
sequências após a aplicação do registro dos termogramas (Seção\emph{
\ref{sec:methodology:image_registration}}). A Figura \ref{fig:methodology:roi:segmentation}
demonstra a etapa de segmentação manual utilizando o mouse para desenhar
o polígono que definirá a ROI. Como resultado uma máscara binária
(Figura \ref{fig:methodology:roi:mask}) é gerada, para ser utilizada
como ROI para todos as 20 sequências de termogramas em um exame. 

\begin{figure}[H]
\hfill{}\subfloat[\label{fig:methodology:roi:segmentation}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/segmentation_click}
\par\end{centering}

}\hfill{}\subfloat[\label{fig:methodology:roi:mask}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/roi_mask}
\par\end{centering}

}\hfill{}

\caption{Extração da região das mamas através do software ImageJ. }



\fonte{\cite{lincoln_thesis2015}}
\end{figure}



\section{Extração de características 1\label{sec:methodology:fps}}

Dado um exame TID, temos 20 sequências de termogramas, cada um correspondendo
à um tempo distinto em ordem sequencial. Precisamos extrair características
que diferenciem as TID de pacientes saudáveis de TID de pacientes
com algum tipo de anomalia. A forma encontrada foi criar um vetor
$p=[I_{1}(i,j),I_{2}(i,j),...I_{20}(i,j)]$, onde $I_{t}(i,j)$ é
o valor de temperatura do termograma de tempo $t$ na posição $(i,j)$.
Dessa forma, podemos extrair 4 valores estatísticos do vetor $p$,
sendo eles:
\begin{itemize}
\item A temperatura de inicial, ou seja, o valor de $I_{1}(i,j).$ Notamos
que a temperatura inicial da sequência de termogramas é um bom descriminador,
pois regiões com anomalias tendem a ficar mais definidas durante o
processo de resfriamento no protocolo de aquisição de imagens e não
possuem regiões equivalentes na mama oposta. A Figura \ref{fig:methodology:fps:feat_1}
mostra a diferença entre uma TID saudável e outra com anomalia.
\item O ganho de temperatura total dado por $G=I_{20}(i,j)-I_{1}(i,j)$.
Essa medida informa o quanto uma dada região se aqueceu ou esfriou
durante o tempo de extração das características. Durante os teste
realizados notamos regiões que sofrem algum tipo de anomalia tendem
a ganhar mais temperatura durante o tempo de extração das imagens.
Em imagens saudáveis quando ocorre esse tipo de comportamento, geralmente
a um tipo de espalhamento, de forma que ele aparece nas duas mamas.
Na Figura \ref{fig:fig:methodology:fps:feat_2:a} vemos uma TID de
paciente saudável. Notamos um aspecto simétrico entre as regiões.
Já a Figura \ref{fig:fig:methodology:fps:feat_2:b} possui uma região
de alto ganho de temperatura em relação as demais da mama, coincidindo
com a região em que o tumor existe. 
\item O ganho médio de temperatura entres os tempos dado pela Equação \ref{eq:methodology:fps:mean_bt}.
Essa característica se assemelha ao ganho total de temperatura, onde
regiões com algum tipo de anomalia tendem ter uma média maior que
as demais regiões e não apresentam uma similaridade na mesma região
da outra mama. A Figura \ref{fig:methodology:fps:feat_3} apresenta
o resultado da extração dessa característica em TID de paciente saudável
e em uma TID de paciente doente.
\item O desvio padrão do ganho de temperatura entres os tempos dada pela
Equação \ref{eq:methodology:fps:std_bt}. Essa característica apresenta
um grande fator de discriminância entres regiões saudáveis e com anomalias.
Regiões saudáveis tendem a ganhar temperatura de forma uniforme durante
a aquisição dos termogramas, ao contrário de regiões anômalas que
variam bastante no ganho de temperatura. Dessa forma regiões saudáveis
apresentam um valor para $S$ mais baixo em relação à regiões que
possuem algum tipo de anomalia. A Figura \ref{fig:methodology:fps:feat_4}
apresenta o desvio padrão do ganho de temperatura em uma TID de paciente
saudável e em uma TID de paciente doente.
\end{itemize}
\begin{equation}
M=\frac{1}{19}\cdot\sum_{t=2}^{20}I_{t}(i,j)-I_{t-1}(i,j)\label{eq:methodology:fps:mean_bt}
\end{equation}


\begin{equation}
S=\sqrt{\frac{1}{19}\cdot\sum_{t=2}^{20}((I_{t}(i,j)-I_{t-1}(i,j))-M)^{2}}\label{eq:methodology:fps:std_bt}
\end{equation}


Essas características quando analisadas em conjunto oferecem um grande
discriminador entre as pacientes. É possível perceber a similaridade
entre as mamas direita e esquerda nas Figuras \ref{fig:methodology:fps:feat_1:a},
\ref{fig:fig:methodology:fps:feat_2:a} e\ref{fig:fig:methodology:fps:feat_3:a},
e uma homogeneidade na Figura \ref{fig:methodology:fps:feat_4:a}.
Essas imagens representam uma paciente saudável. Já nas Figuras \ref{fig:methodology:fps:feat_1:b},\ref{fig:fig:methodology:fps:feat_2:b}
e \ref{fig:fig:methodology:fps:feat_3:b} a similaridade entre as
mamas é quebrada por regiões de pico de valores que são coincidentes
entre elas, e na Figura \ref{fig:methodology:fps:feat_4:b} temos
regiões com uma maior desvio padrão em relação as demais regiões da
mama, coincidindo com as regiões de maior pico nas imagens das outras
características.

\begin{figure}[H]
\hfill{}\subfloat[\label{fig:methodology:fps:feat_1:a}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps1_n}
\par\end{centering}

\centering{}}\hfill{}\subfloat[\label{fig:methodology:fps:feat_1:b}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps1_d}
\par\end{centering}

}\hfill{}

\caption{Temperatura Inicial. Em (a) temos um termograma de paciente saudável,
enquanto em (b) temos uma paciente com carcinoma ductal infiltrante.
Note a assimetria existente em (b). \label{fig:methodology:fps:feat_1}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\begin{OnehalfSpace}
\hfill{}\subfloat[\label{fig:fig:methodology:fps:feat_2:a}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps2_n}
\par\end{centering}

\centering{}}\hfill{}\subfloat[\label{fig:fig:methodology:fps:feat_2:b}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps2_d}
\par\end{centering}

}\hfill{}
\end{OnehalfSpace}

\caption{Ganho de temperatura total. Em (a) temos um termograma de paciente
saudável, enquanto em (b) temos uma paciente com carcinoma ductal
infiltrante. A região mais avermelhada em (b) coincide com a região
em que o tumor aparece. \label{fig:methodology:fps:feat_2}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\hfill{}\subfloat[\label{fig:fig:methodology:fps:feat_3:a}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps3_n}
\par\end{centering}

\centering{}}\hfill{}\subfloat[\label{fig:fig:methodology:fps:feat_3:b}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps3_d}
\par\end{centering}

}\hfill{}

\caption{Ganho de temperatura média entre os tempos da TID. Em (a) vemos um
exame de paciente saudável, enquanto em (b) temos uma paciente com
lesão na mama. \label{fig:methodology:fps:feat_3}}



\fonte{Elaborada pelo autor}
\end{figure}


\begin{figure}[H]
\hfill{}\subfloat[\label{fig:methodology:fps:feat_4:a}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps4_n}
\par\end{centering}

\centering{}}\hfill{}\subfloat[\label{fig:methodology:fps:feat_4:b}]{\begin{centering}
\includegraphics[scale=0.5]{figures/methodology/fps4_d}
\par\end{centering}

}\hfill{}

\caption{Desvio padrão do ganho de temperatura em uma TID. Em (a) temos um
termograma de paciente saudável, enquanto em (b) temos uma paciente
com lesão. \label{fig:methodology:fps:feat_4}}



\fonte{Elaborada pelo autor}
\end{figure}



\section{Extração de Características 2\label{sec:methodology:sps}}

A partir das imagens geradas na Seção \ref{sec:methodology:fps},
são extraídas um conjunto de características baseadas em GLCM, definidas
pelas Equações \ref{eq:fundamentation:glcm:contraste},\ref{eq:fundamentation:glcm:dissimilaridade},\ref{eq:fundamentation:glcm:homogeneidade},\ref{eq:fundamentation:glcm:asm},\ref{eq:fundamentationg:glcm:energia}
e \ref{eq:fundamentationg:glcm:correla=0000E7=0000E3o}. 

Antes de gerarmos as GLCM é necessário converter a escala de valores
para níveis de cinza. Essa conversão é obtida através de

\begin{equation}
X'=a-\frac{(X-X_{min})(b-a)}{X_{max}-X_{min}},\label{eq:methodology:feature_scaling}
\end{equation}


onde $X$ é o conjunto de valores, $X_{min}$ o menor valor valor
do conjunto, $X_{max}$ o maior valor, $b$ o valor máximo desejado
e $a$ o valor mínimo desejado. No caso das imagens extraídas na Seção
\ref{sec:methodology:fps} temos $a=0$ e $b=255$, dessa forma serão
convertidas em níveis de cinza.

A partir das imagens convertidas para valores de níveis de cinza podemos
extrair as GLCM. No total são extraídas 4 matrizes, com distâncias
$(\Delta x=1,\Delta_{y}=0)$, $\Delta x=1,\Delta_{y}=1),$ $\Delta x=0,\Delta_{y}=1)$
e $\Delta x=-1,\Delta_{y}=1)$. A partir daí serão geradas as 6 características
citadas acima para cada matriz, formando um total de 96 características
que serão utilizadas na etapa de classificação da metodologia.


\section{Redução de Características\label{sec:methodology:reduction}}

Essa etapa consiste em reduzir o conjunto de 96 características previamente
extraídas para um conjunto menor e mais conciso de características.
Foram utilizados os 3 métodos descritos na Seção \ref{sec:fundamentation:dimensionality_reduction}.
Dessa forma temos distintos conjuntos de dados que serão utilizados
na etapa de classificação, sendo eles:
\begin{itemize}
\item K-best\emph{ }com $K=40$.
\item K-best com $K=20.$
\item K-best\emph{ }com $K=10$.
\item PCA com $C=20$.
\item PCA com $C=10$.
\item LDA com $C=1$.
\end{itemize}

\section{Classificação}

Essa etapa consiste em classificar um determinado exame TID em saudável
ou doente. Utilizando as características extraídas da Seção \ref{sec:methodology:sps}
e posteriormente reduzidas como entrada para uma SVM. 

Durante essa etapa o conjunto de características originais são subdividas
em 2 conjuntos distintos que chamamos de base de treino e teste, que
não possuem indivíduos em comum entre eles. Antes da etapa de treinamento
de uma SVM, selecionamos as melhores características através de um
dos métodos descritos na Seção \ref{sec:methodology:reduction}. Essa
seleção é feita na base de treino e depois aplicada na base de testes,
dessa forma a base de teste não tem influência na seleção. 

A etapa de treinamento entra em ação, onde a base de treino juntamente
com seus valores de classe é utilizada para encontrar os melhores
vetores de suporte para a SVM. Após o termino do treinamento, a validação
do modelo é executada, onde utilizamos a base de teste sem os valores
de classe como entrada no modelo SVM, que irá classificar os indivíduos
existentes na base. Os resultados são comparados com os valores de
classe conhecidos para validação do modelo. São extraídos os valores
de acurácia (Equação \ref{eq:methodology:classification:acc}) que
mede a taxa de acerto geral, a sensibilidade (Equação \ref{eq:eq:methodology:classification:sensitivity})
que mede a taxa de acerto para os casos que possuem anomalia e a especificidade
(Equação \ref{eq:eq:methodology:classification:specificity}) que
mede a taxa de acerto de casos saudáveis.

\begin{equation}
Acur\acute{a}cia=\frac{TP+TN}{TP+FP+TN+FN}\label{eq:methodology:classification:acc}
\end{equation}


\begin{equation}
Sensibilidade=\frac{TP}{TP+FN}\label{eq:eq:methodology:classification:sensitivity}
\end{equation}


\begin{equation}
Especificidade=\frac{TN}{TN+FP}\label{eq:eq:methodology:classification:specificity}
\end{equation}


onde $TP,TN,FP$ e $FN$ são as quantidades de verdadeiro positivo,
verdadeiro negativo, falso positivo e falso negativo, respectivamente. 


\chapter{Resultados Parciais}

Nesse capítulo são apresentados os resultados parciais da aplicação
da metodologia para a classificação de termografias dinâmicas em saudável
e doente. Os teste são aplicados 100 vezes consecutivas e a média
dos resultados é analisada. Em cada teste, a base é inicialmente dividida
em 80\% dos casos para o treinamento do SVM e 20\% para validação
do modelo. Os indivíduos são selecionados aleatoriamente de forma
que a proporção entre as classes seja mantida. Como a base utilizada
apresenta balanceamento de 1:1 entre as classes, não ocorre o desbalanceamento
na etapa de treinamento e validação. Após a divisão das bases, a redução
de dimensionalidade é utilizada, onde a base de treino é utilizada
como referência para a analise de quais características são as mais
eficientes. As técnicas de redução utilizadas são as descritas na
Seção \ref{sec:methodology:reduction}. Então a base de treino é utilizada
para gerar o modelo SVM, que posteriormente será utilizado na classificação
dos indivíduos. A Tabela \ref{tab:results:mean_table} apresenta os
resultados parciais da metodologia.

\begin{table}[H]
\begin{centering}
\begin{tabular}{|c|c|c|c|}
\hline 
Método & Acurácia & Sensibilidade & Especificidade\tabularnewline
\hline 
\hline 
Sem redução & 42,4\% & 23,7\% & 68,9\%\tabularnewline
\hline 
K-best, K=40 & 48,1\% & 28,1\% & 68,1\%\tabularnewline
\hline 
K-best, K=20 & 49,8\% & 29,1\% & 70,5\%\tabularnewline
\hline 
PCA, K=30 & 48,2\% & 44,1\% & 52,2\%\tabularnewline
\hline 
PCA, K=20 & 47,5\% & 44,7\% & 54,4\%\tabularnewline
\hline 
LDA, K=1 & 78,3\% & 79,9\% & 76,7\%\tabularnewline
\hline 
PCA+LDA, k1= 40, k2=1 & 82,5\% & 84,1\% & 81,0\%\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{Média final da execução dos testes 100 vezes para cada método de seleção
de características.\label{tab:results:mean_table}}
\end{table}


Analisando a tabela, vemos que a estratégia sem reduzir as características
não apresenta bom resultado, ficando abaixo dos 50\% de acurácia.
As técnicas \emph{K-best} e PCA também não produziram resultados satisfatórios.
A técnica de redução que obteve um bom resultado foi a LDA, que sozinho
demonstrou ser a melhor para a redução das características. No entanto,
a combinação da aplicação do PCA seguida da aplicação do LDA foi a
que demonstrou melhores resultados nos testes realizados até o momento,
onde a acurácia, sensibilidade e especificidade ficaram acima dos
80\%. 

Um fator que contribui bastante para os resultados abaixo do esperado
é a quantidade de exames disponíveis. A base utilizada é relativamente
pequena em comparação com bases utilizadas por metodologias baseadas
em mamografia, que chegam a possuir mais de 3000 mil exames disponíveis
para os pesquisadores. Apesar disso, é possível dizer que os resultados
demonstrados são promissores e com a utilização de outras características
que possam discriminar as classes é possível que melhores resultados
sejam obtidos. 


\chapter{Cronograma do Plano de Trabalho}

A plano de trabalho na elaboração da metodologia pode ser subdividido
em:
\begin{enumerate}
\item Pesquisa Bibliográfica
\item Coleta de Dados
\item Elaboração do Projeto de Monografia
\item Revisão Gramatical e Ortográfica
\item Defesa de Monografia
\end{enumerate}
A Tabela\ref{tab:cronograma:plano} apresenta o cronograma de execução
das atividades.

\begin{table}[H]
\begin{centering}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
Etapas & 09/2015 & 10/2015 & 11/2015 & 12/2015 & 01/2016 & 02/2016 & 03/2016 & 04/2016\tabularnewline
\hline 
\hline 
1  & X & X & X &  &  &  &  & \tabularnewline
\hline 
2 &  &  & X & X &  &  &  & \tabularnewline
\hline 
3 &  &  &  & X & X & X &  & \tabularnewline
\hline 
4 &  &  &  &  &  & X & X & \tabularnewline
\hline 
5 &  &  &  &  &  &  &  & X\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{Cronograma do plano de trabalho.\label{tab:cronograma:plano}}
\end{table}



\chapter{Conclusão}

A metodologia apresenta uma forma de auxiliar médicos especialistas
na detecção do câncer de mama. O objetivo não é indicar o local suspeito,
apenas dizer se um determinado paciente apresenta ou não algum tipo
de anomalia na região das mamas. 

A termografia é um exame que não deve ser utilizado isoladamente para
a detecção desse tipo de câncer, mas em conjunto com outros tipos
de exame, como a mamografia. A vantagem desse tipo de imagem é que
o equipamento utilizado para extração das imagens é fácil de carregar,
permitindo a locomoção para diferentes lugares. Apesar disso, é necessário
um ambiente controlado na etapa de extração das imagens. 

O resultados apresentados pela metodologia demonstram ser promissores,
com 82,5\% de acurácia, 84,1 \% de sensibilidade e 81,0\% de especificidade. 


\section{Trabalhos Futuros}

O maior impasse na metodologia é pequena base de imagens previamente
diagnosticadas disponível. Foram utilizadas apenas 70 imagens na metodologia,
longe da quantidade ideal para algoritmos de aprendizado de máquina.
Com a obtenção de novas imagens é possível conseguir melhores resultados.

Novos métricas também podem ser estudadas, com o objetivo de incluí-las
na metodologia apresentada, deixando-a mais robusta e mais precisa.

\bibliographystyle{abntex2-num}
\bibliography{references}

\end{document}
